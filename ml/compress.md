## 降纬技术

### PCA
PCA的优化目标是映射之后使得样本更分散，区分度更大。转换成数学量即映射后的协方差尽量大。

### SVD

SVD与PCA等价，所以PCA问题可以转化为SVD问题求解，那转化为SVD问题有什么好处？

有三点：

- 一般$X$的维度很高,$A^TA$的计算量很大
- 方阵的特征值分解计算效率不高
- SVD除了特征值分解这种求解方式外，还有更高效且更准确的迭代求解法，避免了$A^TA$的计算

其实，PCA只与SVD的右奇异向量的压缩效果相同。
如果取$V$的前k行作为变换矩阵$P_{k\times n}$，则$Y_{k\times m} = P_{k\times n}X_{n\times m}$，起到压缩行即降维的效果
如果取$U$的前d行作为变换矩阵$P_{d\times m}$，则$Y_{n\times d} = X_{n\times m} P_{m\times d}$，起到压缩列即去除冗余样本的效果。

### LDA
与PCA的主要不同之处在于，映射后希望label相同的样本距离尽量小，label不同的样本距离尽量大，即投影后类内方差最小，类间方差最大。